{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1108669,"sourceType":"datasetVersion","datasetId":496640},{"sourceId":6367938,"sourceType":"datasetVersion","datasetId":3668746},{"sourceId":6851382,"sourceType":"datasetVersion","datasetId":3938173}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **PREDICTING HIT SONGS**\n**THERE ARE 3 DATASETS EXTRACTED FROM THE SPOTIFY API:**\n* TRAINING DATASET - ONLY HIT SONGS\n* TESTING DATASET - RANDOM SONGS\n* EVALUATING DATASET - SONGS WITH VIEW COUNT\n|","metadata":{}},{"cell_type":"markdown","source":"**THE WHOLE GOAL WAS TO TRAIN A MODEL ON METADATA OF HIT SONGS LIKE:**\n\n'tempo','key','mode','danceability','valence','energy','acousticness','instrumentalness','liveness','speechiness'","metadata":{}},{"cell_type":"markdown","source":"**PREDICT USING RANDOM SONGS AND MATCH THE RESULT WITH THEIR VIEWS TO CHECK THE ACCURACY OF THE MODEL'S PREDICTION**","metadata":{}},{"cell_type":"markdown","source":"# **KAGGLE START**","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-24T01:11:15.941455Z","iopub.execute_input":"2023-12-24T01:11:15.941796Z","iopub.status.idle":"2023-12-24T01:11:16.277200Z","shell.execute_reply.started":"2023-12-24T01:11:15.941770Z","shell.execute_reply":"2023-12-24T01:11:16.276234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **CONCATENATING THE TRAINING DATASET**","metadata":{}},{"cell_type":"code","source":"hits_dataset_filenames=['dataset-of-10s','dataset-of-00s','dataset-of-90s','dataset-of-80s','dataset-of-70s','dataset-of-60s']\nhits_dataset_dict={}\nfor name in hits_dataset_filenames:\n    df=pd.read_csv(f'/kaggle/input/the-spotify-hit-predictor-dataset/{name}.csv')\n    df.drop(df.iloc[:, 14:18], inplace=True, axis=1)\n    \n    df.drop(['uri'], inplace=True, axis=1)\n    df.drop(['loudness'], inplace=True, axis=1)\n    \n    print(df.shape)\n    hits_dataset_dict[name]=df\n","metadata":{"execution":{"iopub.status.busy":"2023-12-24T01:11:16.278727Z","iopub.execute_input":"2023-12-24T01:11:16.279197Z","iopub.status.idle":"2023-12-24T01:11:16.537439Z","shell.execute_reply.started":"2023-12-24T01:11:16.279155Z","shell.execute_reply":"2023-12-24T01:11:16.536475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **FILTERING THE FEATURES AND SAVING THE TRACK AND NAME**","metadata":{}},{"cell_type":"code","source":"full_hits_dataset = pd.concat(hits_dataset_dict.values(), ignore_index=True, axis=0)\ntrack_artist_fhd=full_hits_dataset.pop('track') +full_hits_dataset.pop('artist')\ntrack_artist_fhd.to_csv('/kaggle/working/track_artist_fhd.csv')\nfull_hits_dataset.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T01:11:38.707351Z","iopub.execute_input":"2023-12-24T01:11:38.707711Z","iopub.status.idle":"2023-12-24T01:11:38.807473Z","shell.execute_reply.started":"2023-12-24T01:11:38.707684Z","shell.execute_reply":"2023-12-24T01:11:38.806471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **FILTERING THE VIEWS DATASET**","metadata":{}},{"cell_type":"code","source":"top_songs_dataset=pd.read_csv('/kaggle/input/top-spotify-songs-2023/spotify-2023.csv',encoding='latin-1')\ntop_songs_views_dataset=top_songs_dataset.pop('streams')\nprint(top_songs_dataset.columns)\ntop_songs_dataset.drop(top_songs_dataset.iloc[:, 2:13], inplace=True, axis=1)\n# top_songs_dataset.drop(['track_id','duration_ms'], inplace=True, axis=1)\n\ntop_songs_dataset.columns","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:48:31.247363Z","iopub.execute_input":"2023-12-23T20:48:31.247738Z","iopub.status.idle":"2023-12-23T20:48:31.265000Z","shell.execute_reply.started":"2023-12-23T20:48:31.247712Z","shell.execute_reply":"2023-12-23T20:48:31.263937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_songs_views_dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:48:31.286180Z","iopub.execute_input":"2023-12-23T20:48:31.286527Z","iopub.status.idle":"2023-12-23T20:48:31.296529Z","shell.execute_reply.started":"2023-12-23T20:48:31.286497Z","shell.execute_reply":"2023-12-23T20:48:31.295361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **FILTERING THE TESTING DATASET**","metadata":{}},{"cell_type":"code","source":"most_songs_dataset=pd.read_csv('/kaggle/input/30000-spotify-songs/spotify_songs.csv')\n\nmost_songs_dataset.drop(most_songs_dataset.iloc[:, 3:11], inplace=True, axis=1)\nmost_songs_dataset.drop(['track_id','duration_ms','loudness'], inplace=True, axis=1)\n\n\n\nmost_songs_dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:48:31.351755Z","iopub.execute_input":"2023-12-23T20:48:31.352160Z","iopub.status.idle":"2023-12-23T20:48:31.527847Z","shell.execute_reply.started":"2023-12-23T20:48:31.352120Z","shell.execute_reply":"2023-12-23T20:48:31.526441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **SORTING THE FEATURES OF THE TRAINGING DATASET AND SAVING THEIR TRACK AND ARTIST**","metadata":{}},{"cell_type":"code","source":"# for l in most_songs_dataset.columns:\n#     for i in most_songs_dataset.columns:\n#         if l!=i:\n#             print(l,i)\nfor l in most_songs_dataset.columns:\n    if l not in full_hits_dataset.columns:\n        print(l)\n        \nmost_songs_dataset.rename(columns={\"track_name\":\"track\",\"track_artist\":\"artist\"}, inplace=True)\nfor l in most_songs_dataset.columns:\n    if l not in full_hits_dataset.columns:\n        print(l)\n        \ntrack_artist_msd=most_songs_dataset.pop('track') +\" \"+ most_songs_dataset.pop('artist') \ntrack_artist_msd.to_csv('/kaggle/working/track_artist_msd.csv')\n\ntrack_artist_msd\n ","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:48:31.529410Z","iopub.execute_input":"2023-12-23T20:48:31.529696Z","iopub.status.idle":"2023-12-23T20:48:31.602199Z","shell.execute_reply.started":"2023-12-23T20:48:31.529654Z","shell.execute_reply":"2023-12-23T20:48:31.601322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **KEY FEATURES THE MODELS WILL BE BASED ON**","metadata":{}},{"cell_type":"code","source":"features=['tempo','key','mode','danceability','valence','energy','acousticness','instrumentalness','liveness','speechiness']","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:48:31.603602Z","iopub.execute_input":"2023-12-23T20:48:31.603915Z","iopub.status.idle":"2023-12-23T20:48:31.609133Z","shell.execute_reply.started":"2023-12-23T20:48:31.603891Z","shell.execute_reply":"2023-12-23T20:48:31.607788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **EXTRACTING THE VIEWS AND THEIR TRACK**","metadata":{}},{"cell_type":"code","source":"#no loudness in this\nfor l in top_songs_dataset.columns:\n    if l not in full_hits_dataset.columns:\n        print(l)\n        \n# top_songs_dataset.rename(columns={\"track_name\":\"track\",\"track_artist\":\"artist\"}, inplace=True)\ntop_songs_dataset\ntop_songs_dataset=top_songs_dataset.set_axis(['track','artist','tempo','key','mode','danceability','valence','energy','acousticness','instrumentalness','liveness','speechiness'], axis=\"columns\")\nfor l in top_songs_dataset.columns:\n    if l not in full_hits_dataset.columns:\n        print(l)\ntrack_artist_tsd=top_songs_dataset.pop('track')+\" \" +top_songs_dataset.pop('artist')\ntrack_artist_tsd.to_csv('/kaggle/working/track_artist_tsd.csv')\ntop_songs_views_dataset=pd.concat([track_artist_tsd,top_songs_views_dataset], axis=1, join=\"inner\",ignore_index=True)\ntop_songs_views_dataset=top_songs_views_dataset.set_axis(['track - artist', 'views'],axis='columns')\ntop_songs_views_dataset.to_csv('/kaggle/working/top_songs_views_dataset.csv')\n\ntop_songs_views_dataset     \n# top_songs_views_dataset.columns","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:48:31.611804Z","iopub.execute_input":"2023-12-23T20:48:31.612157Z","iopub.status.idle":"2023-12-23T20:48:31.640771Z","shell.execute_reply.started":"2023-12-23T20:48:31.612129Z","shell.execute_reply":"2023-12-23T20:48:31.639725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **SPOTIFY'S CHORDS FROM THEIR API**","metadata":{}},{"cell_type":"code","source":"chords=['C','C#','D','D#','E','F','F#','G','G#','A','A#','B']","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:48:31.642308Z","iopub.execute_input":"2023-12-23T20:48:31.642688Z","iopub.status.idle":"2023-12-23T20:48:31.647191Z","shell.execute_reply.started":"2023-12-23T20:48:31.642633Z","shell.execute_reply":"2023-12-23T20:48:31.646556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **PREPROCESSING THE VIEWS DATASET**","metadata":{}},{"cell_type":"code","source":"top_songs_dataset.loc[top_songs_dataset['mode'] == 'Major', 'mode'] = 1\ntop_songs_dataset.loc[top_songs_dataset['mode'] == 'Minor', 'mode'] = 0\ntop_songs_dataset['key'] = top_songs_dataset['key'].fillna(-1)\nfor chord in chords:\n    top_songs_dataset.loc[top_songs_dataset['key'] == chord, 'key'] = chords.index(chord)\nlabs = list(top_songs_dataset.columns)\n\nfor lab in labs:\n    print(top_songs_dataset[lab].unique())","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:48:31.648409Z","iopub.execute_input":"2023-12-23T20:48:31.648680Z","iopub.status.idle":"2023-12-23T20:48:31.673257Z","shell.execute_reply.started":"2023-12-23T20:48:31.648637Z","shell.execute_reply":"2023-12-23T20:48:31.672195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **SORTING THE FEATURES THROUGH ALL DATASETS**","metadata":{}},{"cell_type":"code","source":"feat_dict={}\nfor lab in list(full_hits_dataset.columns):\n    if lab in ['target','tempo','key','mode']: \n        feat_dict[lab]=1\n        continue\n    feat_dict[lab]=100\nfull_hits_dataset.mul(feat_dict)\n# print(len(feat_dict))\nfeat_dict.pop('target')\nprint(feat_dict)\ntop_songs_dataset.mul(feat_dict)\nmost_songs_dataset.mul(feat_dict)\ntop_songs_dataset=top_songs_dataset[most_songs_dataset.columns]\nfull_hits_dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:48:31.716158Z","iopub.execute_input":"2023-12-23T20:48:31.716495Z","iopub.status.idle":"2023-12-23T20:48:31.744676Z","shell.execute_reply.started":"2023-12-23T20:48:31.716468Z","shell.execute_reply":"2023-12-23T20:48:31.743344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **SPLITTING THE TRAINING DATASET**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ny=full_hits_dataset.pop('target')\n# full_hits_dataset.drop(['mode','key'], inplace=True, axis=1)\ny.to_csv('/kaggle/working/target.csv')\ny.to_csv('/kaggle/working/target.csv')\nfull_hits_dataset.to_csv('/kaggle/working/full_hits_dataset.csv')\n\nX_train, X_test, y_train, y_test = train_test_split(full_hits_dataset, y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:48:31.774198Z","iopub.execute_input":"2023-12-23T20:48:31.775116Z","iopub.status.idle":"2023-12-23T20:48:32.042297Z","shell.execute_reply.started":"2023-12-23T20:48:31.775084Z","shell.execute_reply":"2023-12-23T20:48:32.041329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **MODEL AND METRICS**","metadata":{}},{"cell_type":"code","source":"from sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\n\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\nfrom sklearn.linear_model import SGDClassifier\n\nfrom sklearn.ensemble import AdaBoostClassifier\n\nfrom sklearn import svm\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neighbors import RadiusNeighborsClassifier\n\nfrom sklearn.gaussian_process import GaussianProcessClassifier\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:48:32.043943Z","iopub.execute_input":"2023-12-23T20:48:32.044466Z","iopub.status.idle":"2023-12-23T20:48:32.049717Z","shell.execute_reply.started":"2023-12-23T20:48:32.044442Z","shell.execute_reply":"2023-12-23T20:48:32.048684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **WORST MODELS**","metadata":{}},{"cell_type":"code","source":"# GaussianProcessClassifier() too much memory can't run\n# KNeighborsClassifier(),RadiusNeighborsClassifier() no time to try\n\nmodels=[svm.SVC(),svm.NuSVC()]\nfor model in models:\n    dec = model\n    dec=dec.fit(X_train,y_train)\n    y_pred=dec.predict(X_test)\n\n\n    print(classification_report(y_test, y_pred))\n    conf_mat=confusion_matrix(y_test, y_pred)\n    print(conf_mat)\n    print(conf_mat.ravel())","metadata":{"execution":{"iopub.status.busy":"2023-12-21T17:53:02.790753Z","iopub.execute_input":"2023-12-21T17:53:02.791169Z","iopub.status.idle":"2023-12-21T17:55:04.105869Z","shell.execute_reply.started":"2023-12-21T17:53:02.791134Z","shell.execute_reply":"2023-12-21T17:55:04.104915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **BEST MODELS**","metadata":{}},{"cell_type":"code","source":"# HistGradientBoostingClassifier(),RandomForestClassifier(),ExtraTreesClassifier(),GradientBoostingClassifier(),AdaBoostClassifier() best\n# svm.LinearSVC() very good not consistent\n#tree.DecisionTreeClassifier(),SGDClassifier() +\n\n\nmodels=[HistGradientBoostingClassifier(),RandomForestClassifier(),ExtraTreesClassifier(),GradientBoostingClassifier(),AdaBoostClassifier(),svm.LinearSVC(),SGDClassifier(),tree.DecisionTreeClassifier()]\nfor model in models:\n    dec = model\n    dec=dec.fit(X_train,y_train)\n    y_pred=dec.predict(X_test)\n\n\n    print(classification_report(y_test, y_pred))\n    conf_mat=confusion_matrix(y_test, y_pred)\n    print(conf_mat)\n    print(conf_mat.ravel())","metadata":{"execution":{"iopub.status.busy":"2023-12-21T16:53:19.175590Z","iopub.execute_input":"2023-12-21T16:53:19.176052Z","iopub.status.idle":"2023-12-21T16:53:53.004401Z","shell.execute_reply.started":"2023-12-21T16:53:19.176013Z","shell.execute_reply":"2023-12-21T16:53:53.003121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **PREDICTING**","metadata":{}},{"cell_type":"code","source":"pred=[]\nmodels=[HistGradientBoostingClassifier(),RandomForestClassifier()]\n# models=[HistGradientBoostingClassifier()]\nfor model in models:\n    dec = model\n    dec=dec.fit(X_train,y_train)\n    y_pred=dec.predict(most_songs_dataset)\n    pred.append(y_pred)\n\n# full_msd_hgbc=track_artist_msd+most_songs_dataset+y_pred[0]\n# full_msd_rfc=track_artist_msd+most_songs_dataset+y_pred[1]","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:48:35.968032Z","iopub.execute_input":"2023-12-23T20:48:35.968367Z","iopub.status.idle":"2023-12-23T20:48:47.013068Z","shell.execute_reply.started":"2023-12-23T20:48:35.968339Z","shell.execute_reply":"2023-12-23T20:48:47.012068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred[0]=pd.DataFrame(pred[0],columns=['hit'])\npred[1]=pd.DataFrame(pred[1],columns=['hit'])\n","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:48:48.189226Z","iopub.execute_input":"2023-12-23T20:48:48.189600Z","iopub.status.idle":"2023-12-23T20:48:48.195273Z","shell.execute_reply.started":"2023-12-23T20:48:48.189571Z","shell.execute_reply":"2023-12-23T20:48:48.194245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds=[]\nmodels=[HistGradientBoostingClassifier(),RandomForestClassifier()]\n# models=[HistGradientBoostingClassifier()]\nfor model in models:\n    dec = model\n    dec=dec.fit(X_train,y_train)\n    y_pred=dec.predict(top_songs_dataset)\n    preds.append(y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:48:48.636509Z","iopub.execute_input":"2023-12-23T20:48:48.636884Z","iopub.status.idle":"2023-12-23T20:48:58.923254Z","shell.execute_reply.started":"2023-12-23T20:48:48.636853Z","shell.execute_reply":"2023-12-23T20:48:58.921822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds[0]=pd.DataFrame(pred[0],columns=['hit'])\npreds[1]=pd.DataFrame(pred[1],columns=['hit'])","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:49:00.031461Z","iopub.execute_input":"2023-12-23T20:49:00.031843Z","iopub.status.idle":"2023-12-23T20:49:00.037153Z","shell.execute_reply.started":"2023-12-23T20:49:00.031811Z","shell.execute_reply":"2023-12-23T20:49:00.036190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **FINAL PREDICTIONS DATASET**","metadata":{}},{"cell_type":"code","source":"# result = pd.concat([df1, df4], axis=1, join=\"inner\")\n\nfull_msd_hgbc=pd.concat([track_artist_msd,pred[0]], axis=1, join=\"inner\",ignore_index=True)\nfull_msd_rfc=pd.concat([track_artist_msd,pred[1]], axis=1, join=\"inner\",ignore_index=True)\n# full_msd_hgbc.rename(columns={\"0\": \"track - artist\", \"1\": \"Hit\"},inplace=True)\n# full_msd_rfc.rename(columns={\"0\": \"track - artist\", \"1\": \"Hit\"},inplace=True)\nprint(full_msd_hgbc.shape)\nfull_msd_hgbc=full_msd_hgbc.set_axis(['track - artist', 'hit'], axis='columns')\nfull_msd_rfc=full_msd_rfc.set_axis(['track - artist', 'hit'], axis='columns')\n# full_msd_hgbc.compare(full_msd_rfc)\nprint(full_msd_hgbc['track - artist'].isin(top_songs_views_dataset['track - artist'].values).unique(),\nfull_msd_rfc['track - artist'].isin(top_songs_views_dataset['track - artist'].values).unique())","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:49:38.848333Z","iopub.execute_input":"2023-12-23T20:49:38.848709Z","iopub.status.idle":"2023-12-23T20:49:38.862082Z","shell.execute_reply.started":"2023-12-23T20:49:38.848681Z","shell.execute_reply":"2023-12-23T20:49:38.860899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# result = pd.concat([df1, df4], axis=1, join=\"inner\")\n\nfull_tsd_hgbc=pd.concat([track_artist_tsd,preds[0]], axis=1, join=\"inner\",ignore_index=True)\nfull_tsd_rfc=pd.concat([track_artist_tsd,preds[1]], axis=1, join=\"inner\",ignore_index=True)\n# full_msd_hgbc.rename(columns={\"0\": \"track - artist\", \"1\": \"Hit\"},inplace=True)\n# full_msd_rfc.rename(columns={\"0\": \"track - artist\", \"1\": \"Hit\"},inplace=True)\nprint(full_tsd_hgbc.shape)\nfull_tsd_hgbc=full_tsd_hgbc.set_axis(['track - artist', 'hit'], axis='columns')\nfull_tsd_rfc=full_tsd_rfc.set_axis(['track - artist', 'hit'], axis='columns')\n# full_msd_hgbc.compare(full_msd_rfc)\nprint(full_tsd_hgbc['track - artist'].isin(top_songs_views_dataset['track - artist'].values).unique(),\nfull_tsd_rfc['track - artist'].isin(top_songs_views_dataset['track - artist'].values).unique())","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:49:39.235882Z","iopub.execute_input":"2023-12-23T20:49:39.236922Z","iopub.status.idle":"2023-12-23T20:49:39.248486Z","shell.execute_reply.started":"2023-12-23T20:49:39.236883Z","shell.execute_reply":"2023-12-23T20:49:39.247145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **COMPARING THE PREDICTIONS WTH THEIR VIEW COUNT**","metadata":{}},{"cell_type":"code","source":"full_msd_rfc.set_axis(['track - artist', 'hit'],axis='columns')\nfull_msd_hgbc.set_axis(['track - artist', 'hit'],axis='columns')\nprint(top_songs_views_dataset.shape,full_msd_hgbc.shape,full_msd_hgbc['hit'].value_counts(),full_msd_rfc.shape,full_msd_rfc['hit'].value_counts())\nmerged_msd_hgbc = full_msd_hgbc.merge(top_songs_views_dataset,how=\"inner\")\nmerged_msd_rfc=full_msd_rfc.merge(top_songs_views_dataset,how=\"inner\")\nprint(merged_msd_hgbc['hit'].value_counts(),merged_msd_hgbc.shape,\nmerged_msd_rfc['hit'].value_counts(),merged_msd_rfc.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:49:41.352771Z","iopub.execute_input":"2023-12-23T20:49:41.353085Z","iopub.status.idle":"2023-12-23T20:49:41.385212Z","shell.execute_reply.started":"2023-12-23T20:49:41.353062Z","shell.execute_reply":"2023-12-23T20:49:41.384423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_tsd_rfc.set_axis(['track - artist', 'hit'],axis='columns')\nfull_tsd_hgbc.set_axis(['track - artist', 'hit'],axis='columns')\nprint(top_songs_views_dataset.shape,full_tsd_hgbc.shape,full_tsd_hgbc['hit'].value_counts(),full_tsd_rfc.shape,full_tsd_rfc['hit'].value_counts())\nmerged_tsd_hgbc = full_tsd_hgbc.merge(top_songs_views_dataset,how=\"inner\")\nmerged_tsd_rfc=full_tsd_rfc.merge(top_songs_views_dataset,how=\"inner\")\nprint(merged_tsd_hgbc['hit'].value_counts(),merged_tsd_hgbc.shape,\nmerged_tsd_rfc['hit'].value_counts(),merged_tsd_rfc.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:49:43.506468Z","iopub.execute_input":"2023-12-23T20:49:43.506981Z","iopub.status.idle":"2023-12-23T20:49:43.523323Z","shell.execute_reply.started":"2023-12-23T20:49:43.506954Z","shell.execute_reply":"2023-12-23T20:49:43.522024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **FINAL RESULTS**","metadata":{}},{"cell_type":"code","source":"merged_msd_rfc","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:49:49.625643Z","iopub.execute_input":"2023-12-23T20:49:49.626029Z","iopub.status.idle":"2023-12-23T20:49:49.638007Z","shell.execute_reply.started":"2023-12-23T20:49:49.626002Z","shell.execute_reply":"2023-12-23T20:49:49.636930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_tsd_rfc","metadata":{"execution":{"iopub.status.busy":"2023-12-23T20:49:50.606204Z","iopub.execute_input":"2023-12-23T20:49:50.606521Z","iopub.status.idle":"2023-12-23T20:49:50.618720Z","shell.execute_reply.started":"2023-12-23T20:49:50.606495Z","shell.execute_reply":"2023-12-23T20:49:50.617744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **AFTER THIS:**\n* locate songs better\n* add another test dataset to check more precisely\n* explore more nominal data not just numerical data\n* add matplotlib charts for better visualization\n* **and finally publish the blog**","metadata":{}},{"cell_type":"markdown","source":"# **IN THE FUTURE**\n* play around with the modifiers of the two best models\n* try it maybe on the milion song dataset","metadata":{}}]}